{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf8842ea-7b7a-4562-9440-4325028bf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_ernie_models\n",
    "from utils import get_qwen_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "048b4796-9f27-483b-a128-627f6afe7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, chat, embed = get_qwen_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c87c9e75-c271-4455-9f66-b74640dcd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"大语言模型.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae961f-5da7-4c13-8502-5e0231408d0b",
   "metadata": {},
   "source": [
    "### 1. load 加载文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46f018c1-d4ef-4692-b3e5-48bf5b899681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3487d58c-bdf5-43e0-b4f1-ab60ea9da01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_loader = TextLoader(file_path=file_name, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14bbd818-932a-4002-b109-bf9dee1b127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dabeb608-4e58-4b2d-b300-68952e43cc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '大语言模型.txt'}, page_content='大语言模型作为人工智能领域的重要技术之一，具有广泛的应用场景。以下是十个方面的应用场景及其详细描述：\\n\\n1. 机器翻译\\n描述：大语言模型通过训练可以学习不同语言之间的语法和语义规则，实现自动翻译。这种技术已广泛应用于跨国企业沟通、国际合作等领域，如谷歌翻译等产品。尽管在处理长句子和歧义消解等方面仍面临挑战，但随着技术的发展，其准确性和流畅度不断提升。\\n\\n2. 智能客服与聊天机器人\\n描述：大语言模型被用于开发智能客服助手和聊天机器人，能够理解用户的问题并提供相应的解决方案或转达给相关部门。这不仅提高了客服效率，还提升了用户体验。例如，通过自然语言处理技术，智能客服助手可以分析用户情感状态，及时发现问题并优化服务。\\n\\n3. 文本生成与创作\\n描述：大语言模型能够生成符合语法规则的文章、新闻、小说等文本内容。通过学习大量文本数据，模型可以生成具有创造性和相关性的内容，广泛应用于新闻报道、广告营销等领域。此外，它还能根据给定主题或关键词生成文章，为创作者提供灵感和辅助。\\n\\n4. 情感分析\\n描述：大语言模型通过分析文本中的情感倾向和情感表达，帮助企业了解客户反馈和情感状态，从而制定更精准的营销策略或优化客户服务。这种技术还可用于社交媒体监控，实时分析公众对某一主题或事件的情绪和反应。\\n\\n5. 自动问答系统\\n描述：通过学习大量问题和答案，大语言模型能够自动生成符合语法规则的问题和答案。这种自动问答系统可应用于智能助手、搜索引擎等领域，为用户提供高效、准确的信息服务。结合知识图谱技术，问答系统的知识检索和推理能力得到进一步增强。\\n\\n6. 自动摘要与总结\\n描述：大语言模型能够自动对文本进行摘要和总结，提取关键信息，帮助用户快速了解文本主旨和重点。这种技术在学术论文、新闻报道等领域具有重要应用价值，提高了信息获取的效率。\\n\\n7. 代码生成与自动化编程\\n描述：大语言模型通过学习大量代码数据，可以理解编程语言的语法和逻辑规则，实现代码的自动生成。这有助于非技术用户生成基本代码，同时为专业编程人员提供辅助，加快开发进程。然而，在复杂任务中仍需人工审核和调整。\\n\\n8. 信息检索与推荐系统\\n描述：大语言模型可应用于改善搜索引擎结果和内容推荐算法。通过分析用户查询意图和上下文信息，模型能够提供更准确、个性化的搜索结果和内容推荐，提升用户体验和满意度。\\n\\n9. 生物医学研究\\n描述：在生物医学领域，大语言模型可用于分析基因组数据、蛋白质相互作用等，加速药物发现和新疗法的研究。例如，通过预测基因变异的功能影响，研究者能够更全面地分析人类基因组的潜在风险和治疗靶点。\\n\\n10. 语音识别与生成\\n描述：大语言模型在语音识别和语音生成方面也展现出巨大潜力。通过将语音转录为文本或将文本转化为语音，该技术使得人们与计算机的交互更加自然和便捷。这对于有听力或视觉障碍的人群尤为重要，有助于他们更好地理解和享受音视频内容。\\n\\n综上所述，大语言模型在多个领域都具有广泛的应用前景和巨大的价值潜力。随着技术的不断进步和完善，我们有理由相信大语言模型将在未来的人工智能领域发挥更加重要的作用。')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af397e-15e3-4ba9-9c75-6447289bd2be",
   "metadata": {},
   "source": [
    "### 2. split 文本切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27f594e2-d160-4f82-9e47-692afd8475b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b7fe6cd-960c-45c6-b1bf-a35d6f8a792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9322e78-208d-45f2-a35b-303bb43b8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = spliter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ba5072f-605a-45bc-899e-7813c80d86ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440eb6c1-6111-48a9-9cf1-f816cf0c7450",
   "metadata": {},
   "source": [
    "### 3. embed 和 store 向量化和入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "238828fc-b1b6-4b0c-93e3-13a151bc5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from chromadb import Client\n",
    "from chromadb import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b6ea534-7da4-4c4d-b2ce-4c51f4ff86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(chroma_server_host=\"localhost\", chroma_server_http_port=8002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12a18a01-2c71-4703-85d7-e2fe010c402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b10935fe-2f75-43a7-acb8-ae2d81ed4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Chroma(client=client, embedding_function=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b23a5237-84fb-4cae-b29c-e96472b22190",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(2):\n",
    "    store.add_documents(documents=docs[idx * 6: (idx + 1) * 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cc0f8dc-bc2c-4581-b775-b8558168e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfaa5bbf-e99f-4d88-ad51-a29ea326e713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '大语言模型.txt'}, page_content='9. 生物医学研究\\n描述：在生物医学领域，大语言模型可用于分析基因组数据、蛋白质相互作用等，加速药物发现和新疗法的研究。例如，通过预测基因变异的功能影响，研究者能够更全面地分析人类基因组的潜在风险和治疗靶点。\\n\\n10. 语音识别与生成\\n描述：大语言模型在语音识别和语音生成方面也展现出巨大潜力。通过将语音转录为文本或将文本转化为语音，该技术使得人们与计算机的交互更加自然和便捷。这对于有听力或视觉障碍的人群尤为重要，有助于他们更好地理解和享受音视频内容。'),\n",
       " Document(metadata={'source': '大语言模型.txt'}, page_content='8. 信息检索与推荐系统\\n描述：大语言模型可应用于改善搜索引擎结果和内容推荐算法。通过分析用户查询意图和上下文信息，模型能够提供更准确、个性化的搜索结果和内容推荐，提升用户体验和满意度。\\n\\n9. 生物医学研究\\n描述：在生物医学领域，大语言模型可用于分析基因组数据、蛋白质相互作用等，加速药物发现和新疗法的研究。例如，通过预测基因变异的功能影响，研究者能够更全面地分析人类基因组的潜在风险和治疗靶点。'),\n",
       " Document(metadata={'source': '大语言模型.txt'}, page_content='大语言模型作为人工智能领域的重要技术之一，具有广泛的应用场景。以下是十个方面的应用场景及其详细描述：\\n\\n1. 机器翻译\\n描述：大语言模型通过训练可以学习不同语言之间的语法和语义规则，实现自动翻译。这种技术已广泛应用于跨国企业沟通、国际合作等领域，如谷歌翻译等产品。尽管在处理长句子和歧义消解等方面仍面临挑战，但随着技术的发展，其准确性和流畅度不断提升。'),\n",
       " Document(metadata={'source': '大语言模型.txt'}, page_content='10. 语音识别与生成\\n描述：大语言模型在语音识别和语音生成方面也展现出巨大潜力。通过将语音转录为文本或将文本转化为语音，该技术使得人们与计算机的交互更加自然和便捷。这对于有听力或视觉障碍的人群尤为重要，有助于他们更好地理解和享受音视频内容。\\n\\n综上所述，大语言模型在多个领域都具有广泛的应用前景和巨大的价值潜力。随着技术的不断进步和完善，我们有理由相信大语言模型将在未来的人工智能领域发挥更加重要的作用。')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(input=\"大模型在生物医学研究中有什么应用？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73e60b-f353-4b67-8584-f0e3430ff99a",
   "metadata": {},
   "source": [
    "### 4. 构建RAG链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df12d16f-04a7-4684-aa0a-dac9fa277292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22c6ff5a-5f73-4f6d-916a-cf82282cd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"\"\"Answer any user questions based solely on the context below:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\"\"\"),\n",
    "  (\"placeholder\", \"{chat_history}\"),\n",
    "  (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "006c0861-01e5-4b6e-abb4-9f569d71cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = create_stuff_documents_chain(llm=chat, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99072208-6ced-43eb-9b17-0870a2ce4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4dd4227-d440-417c-97b9-aef0adccdae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '今天太原的温度是多少？',\n",
       " 'context': [Document(metadata={'source': '大语言模型.txt'}, page_content='2. 智能客服与聊天机器人\\n描述：大语言模型被用于开发智能客服助手和聊天机器人，能够理解用户的问题并提供相应的解决方案或转达给相关部门。这不仅提高了客服效率，还提升了用户体验。例如，通过自然语言处理技术，智能客服助手可以分析用户情感状态，及时发现问题并优化服务。'),\n",
       "  Document(metadata={'source': '大语言模型.txt'}, page_content='4. 情感分析\\n描述：大语言模型通过分析文本中的情感倾向和情感表达，帮助企业了解客户反馈和情感状态，从而制定更精准的营销策略或优化客户服务。这种技术还可用于社交媒体监控，实时分析公众对某一主题或事件的情绪和反应。\\n\\n5. 自动问答系统\\n描述：通过学习大量问题和答案，大语言模型能够自动生成符合语法规则的问题和答案。这种自动问答系统可应用于智能助手、搜索引擎等领域，为用户提供高效、准确的信息服务。结合知识图谱技术，问答系统的知识检索和推理能力得到进一步增强。'),\n",
       "  Document(metadata={'source': '大语言模型.txt'}, page_content='3. 文本生成与创作\\n描述：大语言模型能够生成符合语法规则的文章、新闻、小说等文本内容。通过学习大量文本数据，模型可以生成具有创造性和相关性的内容，广泛应用于新闻报道、广告营销等领域。此外，它还能根据给定主题或关键词生成文章，为创作者提供灵感和辅助。\\n\\n4. 情感分析\\n描述：大语言模型通过分析文本中的情感倾向和情感表达，帮助企业了解客户反馈和情感状态，从而制定更精准的营销策略或优化客户服务。这种技术还可用于社交媒体监控，实时分析公众对某一主题或事件的情绪和反应。'),\n",
       "  Document(metadata={'source': '大语言模型.txt'}, page_content='5. 自动问答系统\\n描述：通过学习大量问题和答案，大语言模型能够自动生成符合语法规则的问题和答案。这种自动问答系统可应用于智能助手、搜索引擎等领域，为用户提供高效、准确的信息服务。结合知识图谱技术，问答系统的知识检索和推理能力得到进一步增强。\\n\\n6. 自动摘要与总结\\n描述：大语言模型能够自动对文本进行摘要和总结，提取关键信息，帮助用户快速了解文本主旨和重点。这种技术在学术论文、新闻报道等领域具有重要应用价值，提高了信息获取的效率。')],\n",
       " 'answer': '对不起，我无法提供即时天气信息。您可以查询相关的天气预报网站或使用手机上的天气应用程序来获取太原今天的气温。'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"input\": \"今天太原的温度是多少？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2977e-89a2-4bf0-b018-6d51f1d113f9",
   "metadata": {},
   "source": [
    "### 5. 关于 retriever 的一些其他的尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7386cadd-1236-461d-b7da-265e1cce916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009ef8d-e894-4cfe-9e6e-6d415db38e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b6d38-aed5-4351-a495-d1b38acb2748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fa3330d-cd03-40cd-a315-d4ff48130391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGiven a query, use an LLM to write a set of queries.\\nRetrieve docs for each query. Return the unique union of all retrieved docs.\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given a query, use an LLM to write a set of queries.\n",
    "Retrieve docs for each query. Return the unique union of all retrieved docs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "115e7ef7-02b1-43b2-a069-b6b0a80a0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# muti_query_retriever = MultiQueryRetriever(retriever=retriever, llm_chain=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "578899b6-4b39-4088-8c45-3b1a6e40a33e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m muti_query_retriever\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m中国的首都在哪里？\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:251\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    250\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    254\u001b[0m         result,\n\u001b[0;32m    255\u001b[0m     )\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:244\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 244\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    246\u001b[0m     )\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain\\retrievers\\multi_query.py:168\u001b[0m, in \u001b[0;36mMultiQueryRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    156\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    158\u001b[0m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[0;32m    159\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get relevant documents given a user query.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m        Unique union of relevant documents from all generated queries\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_queries(query, run_manager)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_original:\n\u001b[0;32m    170\u001b[0m         queries\u001b[38;5;241m.\u001b[39mappend(query)\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain\\retrievers\\multi_query.py:185\u001b[0m, in \u001b[0;36mMultiQueryRetriever.generate_queries\u001b[1;34m(self, question, run_manager)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_queries\u001b[39m(\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate queries based upon user input.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m        List of LLM generated queries that are similar to the user input\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    186\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain, LLMChain):\n\u001b[0;32m    189\u001b[0m         lines \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:345\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    342\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m--> 345\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    346\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    347\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    348\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    349\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    350\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    351\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    352\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    353\u001b[0m         )\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    356\u001b[0m     )\n",
      "File \u001b[1;32mD:\\software\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:329\u001b[0m, in \u001b[0;36mBaseLLM._convert_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mconvert_to_messages(\u001b[38;5;28minput\u001b[39m))\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "muti_query_retriever.invoke(\"中国的首都在哪里？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b301d40-4935-46e4-838e-28581f119ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a870c7-67b5-4aa8-a4b3-07bdafa7c69a",
   "metadata": {},
   "source": [
    "### 插曲：如何自定义一个retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf36fc33-3817-4abd-8bef-ef2de7086ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "# 列表类\n",
    "from typing import List\n",
    "\n",
    "class SimpleRetriever(BaseRetriever):\n",
    "    # 类变量\n",
    "    docs: List[Document]\n",
    "    k: int = 5\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Return the first k documents from the list of documents\"\"\"\n",
    "        return self.docs[:self.k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"(Optional) async native implementation.\"\"\"\n",
    "        return self.docs[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d0e6c-7788-4b82-af65-bc0e7cd8c4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
