1. 如何求函数最小值？
    - 求解方法：
      - 第一步：求导
      - 第二步：令导数等于0
      - 第三步：解方程，求出极值点
      - 第四步：验证该点是否是极值点以及什么极值点
    - 上述方法的前提条件：
      - 可导，
      - 令（偏）导数=0，方程组可解
    - 换个思路
      - 随机选择一个初始点X0
      - 如果X0在最小值的左侧，则应该每次加上一个小正数，此时导数为负，则可以认为是减去导数
      - 如果X0在最小值的右侧，则应该每次减去一个小正数，此时导数为正，则可以认为是减去导数
      - 如果X0是最小值处，则导数为0，也可以认为是减去导数
    - 补充结论
      - 一元函数，称为导数；多元函数称为偏导数，也就是梯度
      - 减去导数=减去梯度，这就是梯度下降！！！！！！（先求梯度，然后让梯度下降）
2. 理论数学与工程数学的区别：如果函数有9B变量，可以迭代实现，使用GPU
3.  感知机 Perception， 一层全连接， 稠密层: 相乘再相加过程，同时是向量求内积的过程
4. 特别说明
   - 在训练时，X，y 是训练集中的特征和标签，看作常量； w和b是变量，待优化的值
   - 在推理时， w和b已经找到了比较合适的值，已经固定下来了，看作常量，此时，x是待预测样本的特征，是变量；预测的本质就是把x带入，求解y
   - 如何训练？有监督训练的过程：
     - 从训练集中取出一对x和y
     - 把x带入模型，求解预测结果y_pred
     - 想办法度量y_pred与y的误差loss
     - 特别说明：loss是y_pred与y相关的函数，y_pred是模型预测的结果，是w和b的函数；简单来说loss也是w和b的函数！！
     - 训练的本质求解何时loss函数最小，不断让loss减少的过程：当w和b取得什么值时，loss最小！！！求loss函数最小值问题
     - 
     - 
5. 深度学习的基本流程
   - 模型 model:
     - 只负责正向传播forward propagation，不负责反向传播 backward propagation
     - 正向传播：把特征X带入模型model，得到预测结果y_pred
       - 训练时：自动在底层构建计算图（把正向传播的流程记录下来，方便进行后续的分布求导）
       - h(g(f(x))) =h'(g(f(x))*g'(f(x))f'(x),按层更容易求导，分步求导，链式求导
       - 推理时：直接调用正向传播即可，不需要构建计算图
     - 反向传播：本质是计算每个参数的梯度，是通过loss函数发起的！！！
   - 训练流程：
     - 从训练集中取一批batch样本（x, y）
     - 把样本x送入模型model，得到预测结果y_pred
     - 通过损失函数，计算当前误差 loss = f(y_pred, y)
     - 通过loss, 反向传播，计算每个参数（w, b）的梯度
     - 利用优化器optimizer,通过梯度下降法，更新参数
     - 利用优化器optimizer 清空参数梯度
     - 重复以上过程，直至迭代结束（各项指标满足要求）
   - 推理流程
     - 拿到待测样本X（推理时，没有标签，只有特征）
     - 把样本特征X送入模型model,得到预测结果y_pred
     - 根据y_pred解析并返回预测结果
6.深度学习的项目流程
     - 批量化打包数据
       - 使用生成器来打包数据，通过某种规则调用数据，流式处理
       - 实现自定义dataset, 再定义dataloader
     - 搭建模型
       - sequential序贯模型，顺序模型（每个层都可看作一个模型）
       - class:自定义模型
     - 定义损失函数和优化器
       - 损失函数：MSE和CE
       - 优化器：SGD， Adam
       - 训练轮次，学习率
     - 训练模型
       - 训练过程查看监控指标：如准确率，损失率
       - 训练过程中需要保持模型参数，方便后续推理
       - 避免过拟合
     - 推理模型
       - 带入
7.回调函数
     - 回调函数分为定义和调用两个过程
       - 由用户定义，由系统来调用
       - 你定义一个函数，挂载一个地方，系统在合适的时机，调用它
       - 一般来说，回调函数都不应该又用户主动调用！！
8.神经网络
     - n_classes个类别预测问题，模型会输出n_classes个概率
9.交叉熵 cross entropy???
     - 作用：从分布的角度来衡量两个概率的远近程度,衡量两个概率分布之间的差异
     - y_true=2, pred_1 = [12.5, -0.5, 2.7], pred_2 = [-12.5, 6.4, 2.7]
10.Relu, softmax, sigmod激活函数
     - sigmod, S 曲线（0,1），存在激活死区
     - tanh 双曲正切, s曲线（-1,1),存在激活死区
     - Relu 修正的线性单元: >=0 y=x, <0, y=0;存在很多变体
11.数据结构
     - 表格类数据：
       - 成行成列，一行一个样本，一列一个特征；特征之间互相独立，互不影响
       - 解决办法：机器学习算法，深度学习当中的全连接网络（几个线性层堆叠在一起）
     - 时序类数据 sequential data: 机器学习处理这种问题会丢掉顺序，比如bow,效果会变差
       - 一维信号，在一个方向上不能随便改变顺序
       - 特征之间存在某种前后依赖关系
       - 特征之间不是互相独立
       - 自然语言处理NLP Nature Language Processing
         - 股票
         - 声音
         - 音乐，节奏
       - 解决办法：
         - 循环神经网络RNN
         - transformer
     - 图像类数据 image data:
       - 二维信号：在两个方向上，不能随意改变顺序，比如图片改变像素行列，会破坏原来的信息
       - 图像，视频
         - 相机拍摄
         - 红外线成像
         - 雷达成像
         - X光成像
         - ......
       - 计算机视觉CV computer vision