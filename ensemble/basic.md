1. 中心化： 减去均值
2. 归一化： 减去最小值，除以max减去mean
3. 标准化：减去均值，除以标准差或着标准差+1e-9 

4. 监督学习：分类与回归
5. 无监督学习：聚类与降维算法
6. 自监督 self-supervised
    - 大模型预训练时，使用自监督
    - 输入文本，自己挖空填空
7. 线性回归的权重 weight与偏置bias，线性回归可作为神经网络的感知机层/全连接层/稠密层(采用迭代法)
8. 逻辑回归：解决二分类问题
9. 特征分析：乳腺癌数据，30个特征来自鱼临床一线专家，每个特征都有医学内涵，但在数据伤，可能存在一些冗余特征
10. 消除冗余的方法：特征筛选（feature importance 计算两两向量协方差，去掉高度相似的，线性回归计算权重，决策树），特征降维(30个特征中的核心信息抽取出来，融合到新生成的几个特征中，新的特征不是原来的任何一个)
11. 特征降维：SVD 奇异值分解，矩阵计算？？ PCA降维
12. 人工智能三次技术高潮：机器学习，深度学习，大模型
13. voting, bagging(数据采样存在误差), boosting(提升), stacking(堆叠，基础模型，第二阶段模型)
14. boosting 梯度提升：每一次都强化上一次错误，使用的均是迭代算法
15. 随机森林：性能指标：准确率，推理速度，训练速度；推理速度很快，性能指标往往是最优的，相对比较理想
      - 随机：样本级随机
      - 特征级随机：行列都做了随机
16. SVM：推理速度与训练速度都比较慢，准确率比较高