1. 如何求函数最小值？
    - 求解方法：
      - 第一步：求导
      - 第二步：另导数等于0
      - 第三步：解方程，求出极值点
      - 第四步：验证该点是否是极值点以及什么极值点
    - 上述方法的前提条件：
      - 可导，
      - 令（偏）导数=0，方程组可解
    - 换个思路
      - 随机选择一个初始点X0
      - 如果X0在最小值的左侧，则应该每次加上一个小正数，此时导数为负，则可以认为是减去导数
      - 如果X0在最小值的右侧，则应该每次减去一个小正数，此时导数为正，则可以认为是减去导数
      - 如果X0是最小值处，则导数为0，也可以认为是减去导数
    - 补充结论
      - 一元函数，成为导数；多元函数称为偏导数，也就是梯度
      - 减去导数=减去梯度，这就是梯度下降！！！！！！（先求梯度，然后让梯度下降）
2. 理论数学与工程数学的区别：如果函数有9B变量，可以迭代实现，使用GPU
3.  感知机， 一层全连接， 稠密层: 相乘再相加过程，同时是向量求内积的过程
4. 特别说明
   - 在训练时，X，y 是训练集中的特征和标签，看作常量； w和b是变量，待优化的值
   - 在推理时， w和b已经找到了比较合适的值，已经固定下来了，看作常量，此时，x是待预测样本的特征，是变量；预测的本质就是把x带入，求解y
   - 如何训练？有监督训练的过程：
     - 从训练集中取出一对x和y
     - 把x带入模型，求解预测结果y_pred
     - 想办法度量y_pred与y的误差loss
     - 特别说明：loss是y_pred与y相关的函数，y_pred是模型预测的结果，是w和b的函数；简单来说loss也是w和b的函数！！
     - 训练的本质求解何时loss函数最小，不断让loss减少的过程：当w和b取得什么值时，loss最小！！！求loss函数最小值问题
     - 
     - 
   - 